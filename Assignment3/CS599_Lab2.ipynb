{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6WVMk-PG2am"
      },
      "source": [
        "# CS 599 — Lab 2 Catastrophic Forgetting with MLPs on Permuted-MNIST"
      ],
      "id": "d6WVMk-PG2am"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "BwpPlNzL_U4v"
      },
      "id": "BwpPlNzL_U4v"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import List, Tuple\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FkzPzU11HDPK"
      },
      "id": "FkzPzU11HDPK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set configs as well as seeding"
      ],
      "metadata": {
        "id": "fR8YEhXC_Xf1"
      },
      "id": "fR8YEhXC_Xf1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SzwqHgyRG2an"
      },
      "source": [
        "#CONFIG & SEEDING\n",
        "N_TASKS        = 10                # number of permuted-MNIST tasks\n",
        "HIDDEN_UNITS   = 256               # units per hidden layer\n",
        "DEPTHS         = [2, 3, 4]         # number of hidden layers to compare\n",
        "DROPOUT_PS     = [0.0, 0.2, 0.5]   # <= 0.5 as per assignment\n",
        "LOSSES         = [\"nll\", \"l1\", \"l2\", \"l1+l2\"]\n",
        "OPTIMIZERS     = [\"sgd\", \"adam\", \"rmsprop\"]\n",
        "SEED           = 546               # Unique seed\n",
        "EPOCHS_FIRST   = 50                # Task A epochs\n",
        "EPOCHS_OTHERS  = 20                # Tasks B..J epochs\n",
        "BATCH_SIZE     = 128               # typical value; adjust as needed\n",
        "VAL_SPLIT      = 0.1               # hold-out for validation curves\n",
        "LR             = 1e-3              # Learning rate\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "id": "SzwqHgyRG2an",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load MNIST dataset, make and apply permutations to data set and build tasks"
      ],
      "metadata": {
        "id": "nOITsIkp_bCP"
      },
      "id": "nOITsIkp_bCP"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_mnist():\n",
        "    (xtr, ytr), (xte, yte) = tf.keras.datasets.mnist.load_data()\n",
        "    xtr = xtr.astype('float32') / 255.0\n",
        "    xte = xte.astype('float32') / 255.0\n",
        "    xtr = xtr.reshape((-1, 784))\n",
        "    xte = xte.reshape((-1, 784))\n",
        "    return (xtr, ytr), (xte, yte)\n",
        "\n",
        "def make_permutation(dim: int, seed: int):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    return rng.permutation(dim)\n",
        "\n",
        "def apply_perm(X: np.ndarray, perm: np.ndarray):\n",
        "    return X[:, perm]\n",
        "\n",
        "(BASE_XTR, BASE_YTR), (BASE_XTE, BASE_YTE) = load_mnist()\n",
        "\n",
        "def build_tasks(n_tasks: int, base_seed: int):\n",
        "    xtr, ytr = BASE_XTR, BASE_YTR\n",
        "    xte, yte = BASE_XTE, BASE_YTE\n",
        "    tasks = []\n",
        "    for t in range(n_tasks):\n",
        "        perm = make_permutation(784, base_seed + t)\n",
        "        Xtr_t = apply_perm(xtr, perm)\n",
        "        Xte_t = apply_perm(xte, perm)\n",
        "        tasks.append(((Xtr_t, ytr), (Xte_t, yte), perm))\n",
        "    return tasks\n",
        "\n",
        "tasks = build_tasks(N_TASKS, SEED)\n",
        "len(tasks), tasks[0][0][0].shape\n"
      ],
      "metadata": {
        "id": "u0-rE1FZIzhK"
      },
      "id": "u0-rE1FZIzhK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization Help or original data vs permutation"
      ],
      "metadata": {
        "id": "e7nlqYBKscji"
      },
      "id": "e7nlqYBKscji"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_original_and_permuted(task_id=0, idx=0, split='train'):\n",
        "    perm = tasks[task_id][2]\n",
        "\n",
        "    if split == 'train':\n",
        "        x_orig = BASE_XTR[idx]\n",
        "        y_label = int(BASE_YTR[idx])\n",
        "    else:\n",
        "        x_orig = BASE_XTE[idx]\n",
        "        y_label = int(BASE_YTE[idx])\n",
        "\n",
        "    x_perm = x_orig[perm]\n",
        "\n",
        "    img_orig = x_orig.reshape(28, 28)\n",
        "    img_perm = x_perm.reshape(28, 28)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "    axes[0].imshow(img_orig, cmap='gray', interpolation='nearest')\n",
        "    axes[0].set_title(f'Original (label={y_label})')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(img_perm, cmap='gray', interpolation='nearest')\n",
        "    axes[1].set_title(f'Permuted (task {task_id})')\n",
        "    axes[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_original_and_permuted(task_id=0, idx=0, split='train')\n"
      ],
      "metadata": {
        "id": "FQGM7vFGsR-p"
      },
      "id": "FQGM7vFGsR-p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Training and Validation Splits"
      ],
      "metadata": {
        "id": "bJMZ-Zdw_iJK"
      },
      "id": "bJMZ-Zdw_iJK"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tfds(X, y, batch_size = BATCH_SIZE, shuffle=True):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((X,y))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(min(10000, len(X)), seed=SEED, reshuffle_each_iteration=True)\n",
        "  ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "def train_val_split(X, y, val_split = VAL_SPLIT):\n",
        "  n = len(X)\n",
        "  n_val = int(n * val_split)\n",
        "  index = np.arange(n)\n",
        "  rng = np.random.RandomState(SEED)\n",
        "  rng.shuffle(index)\n",
        "  val_index = index[:n_val]\n",
        "  train_index = index[n_val:]\n",
        "\n",
        "  return ((X[train_index], y[train_index]), (X[val_index], y[val_index]))\n"
      ],
      "metadata": {
        "id": "FQZ6WKkYq4ML"
      },
      "id": "FQZ6WKkYq4ML",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build model as well as Regularizers"
      ],
      "metadata": {
        "id": "vE7olqIA_mP5"
      },
      "id": "vE7olqIA_mP5"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp(depth: int, hidden: int = HIDDEN_UNITS, dropout_p: float = 0.0, regularizer=None):\n",
        "  assert depth in (2,3,4)\n",
        "  inputs = tf.keras.Input(shape=(784,))\n",
        "  x = inputs\n",
        "\n",
        "  for _ in range(depth):\n",
        "    x = tf.keras.layers.Dense(hidden, activation='relu', kernel_regularizer=regularizer)(x)\n",
        "    if dropout_p > 0:\n",
        "      x = tf.keras.layers.Dropout(dropout_p)(x)\n",
        "\n",
        "  logits = tf.keras.layers.Dense(10, activation=None)(x)\n",
        "  return tf.keras.Model(inputs, logits)\n",
        "\n",
        "def make_regularizer(loss_name: str, alpha: float = 1e-4):\n",
        "  if loss_name.lower() == \"l1\":\n",
        "    return tf.keras.regularizers.l1(alpha)\n",
        "  if loss_name.lower()  == \"l2\":\n",
        "    return tf.keras.regularizers.l2(alpha)\n",
        "  if loss_name.lower()  == \"l1+l2\":\n",
        "    return tf.keras.regularizers.l1_l2(l1=alpha, l2=alpha)\n",
        "  return None"
      ],
      "metadata": {
        "id": "23njWjpjs6QO"
      },
      "id": "23njWjpjs6QO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make optimizers and loss functions"
      ],
      "metadata": {
        "id": "BRejd7JO_pEX"
      },
      "id": "BRejd7JO_pEX"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_optimizer(name:str, lr: float = LR):\n",
        "  if name == \"sgd\":\n",
        "    return tf.keras.optimizers.SGD(lr, momentum=0.9)\n",
        "  if name == \"adam\":\n",
        "    return tf.keras.optimizers.Adam(lr)\n",
        "  if name == \"rmsprop\":\n",
        "    return tf.keras.optimizers.RMSprop(lr)\n",
        "  return None\n",
        "\n",
        "def make_primary_loss(loss_name: str):\n",
        "  return tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "tQZicYEguC6g"
      },
      "id": "tQZicYEguC6g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model and evaluate"
      ],
      "metadata": {
        "id": "JKHcspxr_rDw"
      },
      "id": "JKHcspxr_rDw"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_on_task(model, Xtr, ytr, epochs: int, optimizer, loss_fn, val_split=VAL_SPLIT):\n",
        "    (Xtr_s, ytr_s), (Xval, yval) = train_val_split(Xtr, ytr, val_split)\n",
        "    ds_train = make_tfds(Xtr_s, ytr_s, shuffle=True)\n",
        "    ds_val = make_tfds(Xval, yval, shuffle=False)\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
        "    hist = model.fit(ds_train, epochs=epochs, validation_data=ds_val, verbose=2)\n",
        "    return hist.history\n",
        "\n",
        "def evaluate_on_task(model, Xte, yte) -> float:\n",
        "    ds_test = make_tfds(Xte, yte, shuffle=False)\n",
        "    _, acc = model.evaluate(ds_test, verbose=0)\n",
        "    return float(acc)\n"
      ],
      "metadata": {
        "id": "-1HAHVLQuuxK"
      },
      "id": "-1HAHVLQuuxK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run baseline model training, Compute accuracy"
      ],
      "metadata": {
        "id": "0lWRM5mk_uZC"
      },
      "id": "0lWRM5mk_uZC"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_sequential_training(depth: int, dropout_p: float, loss_name: str, opt_name: str,\n",
        "                            epochs_first=EPOCHS_FIRST, epochs_others=EPOCHS_OTHERS):\n",
        "    reg = make_regularizer(loss_name)\n",
        "    model = build_mlp(depth, HIDDEN_UNITS, dropout_p, regularizer=reg)\n",
        "    opt = make_optimizer(opt_name, LR)\n",
        "    loss = make_primary_loss(loss_name)\n",
        "\n",
        "    R = np.zeros((N_TASKS, N_TASKS), dtype=np.float32)\n",
        "    histories = []\n",
        "\n",
        "    for i, task in enumerate(tasks):\n",
        "        (Xtr, ytr), (Xte, yte), _ = task\n",
        "        epochs = epochs_first if i == 0 else epochs_others\n",
        "        hist = train_on_task(model, Xtr, ytr, epochs, opt, loss)\n",
        "        histories.append(hist)\n",
        "        for j in range(i + 1):\n",
        "            (Xtr_j, ytr_j), (Xte_j, yte_j), _ = tasks[j]\n",
        "            R[i, j] = evaluate_on_task(model, Xte_j, yte_j)\n",
        "\n",
        "    return model, R, histories\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Baseline Run: Depth = 3, dropout = 0.2\")\n",
        "model, R, histories = run_sequential_training(depth=3, dropout_p=0.2, loss_name=\"nll\", opt_name=\"adam\")\n",
        "\n",
        "def compute_ACC(R):\n",
        "  T = R.shape[0]\n",
        "  return float(np.mean(R[T-1, :T]))\n",
        "\n",
        "def compute_BWT(R):\n",
        "  diag = np.diag(R)\n",
        "  T = R.shape[0]\n",
        "  return float(np.mean(R[T-1, :T-1] - diag[:T-1]))\n",
        "\n",
        "ACC = compute_ACC(R)\n",
        "BTW = compute_BWT(R)\n",
        "print(f\"ACC = {ACC:.4f}\")\n",
        "print(f\"BTW = {BTW:.4f}\")\n",
        "\n",
        "\n",
        "ACC, BWT = compute_ACC(R), compute_BWT(R)\n",
        "print(f\"ACC={ACC:.4f}, BWT={BWT:+.4f}\")\n"
      ],
      "metadata": {
        "id": "yKBHHk1zu4qj"
      },
      "id": "yKBHHk1zu4qj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLot accuracy matrix and forgetting curves"
      ],
      "metadata": {
        "id": "ezzXxmbJ_zCk"
      },
      "id": "ezzXxmbJ_zCk"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(R, vmin=0, vmax=1, aspect='auto')\n",
        "plt.colorbar(label='Accuracy')\n",
        "plt.xlabel('Task j')\n",
        "plt.ylabel('After Task i')\n",
        "plt.title('Accuracy matrix R')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "T = R.shape[0]\n",
        "for j in range(T):\n",
        "\n",
        "    xs = np.arange(j, T)\n",
        "    ys = R[j:T, j]\n",
        "    plt.plot(xs, ys, label=f'T{j}')\n",
        "plt.xlabel('After Task i')\n",
        "plt.ylabel('Accuracy on Task j')\n",
        "plt.title('Forgetting curves (per task)')\n",
        "plt.legend(ncol=2, fontsize=8)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "F = np.max(R[:-1, :], axis=0) - R[T-1, :]\n",
        "for j, f in enumerate(F):\n",
        "    print(f\"Task {j}: forgetting = {f:+.4f}\")\n",
        "print(\"Mean forgetting:\", float(np.mean(F)))\n"
      ],
      "metadata": {
        "id": "yION745qm7K-"
      },
      "id": "yION745qm7K-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run different experiments"
      ],
      "metadata": {
        "id": "MQtED8SX_4cD"
      },
      "id": "MQtED8SX_4cD"
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = dict(depth=3, dropout_p=0.2, loss_name=\"nll\", opt_name=\"adam\")\n",
        "def eval_config(tag, **kw):\n",
        "    cfg = BASE | kw\n",
        "    model, R, _ = run_sequential_training(**cfg)\n",
        "    ACC, BWT = compute_ACC(R), compute_BWT(R)\n",
        "    return dict(tag=tag, **cfg, ACC=ACC, BWT=BWT, R_=R)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Depth: 2, 3, 4\n",
        "for d in [2, 3, 4]:\n",
        "  print(f\"Running at Depth: {d}\")\n",
        "  print(\"\\n\")\n",
        "  results.append(eval_config(f\"depth_{d}\", depth=d))\n",
        "\n",
        "# Regularizer: none/L1/L2/L1+L2\n",
        "for reg in [\"nll\",\"l1\",\"l2\",\"l1+l2\"]:\n",
        "    print(f\"Running at Regularizer: {reg}\")\n",
        "    print(\"\\n\")\n",
        "    results.append(eval_config(f\"reg_{reg}\", loss_name=reg))\n",
        "\n",
        "# Dropout: 0.0, 0.2, 0.5\n",
        "for p in [0.0, 0.2, 0.5]:\n",
        "    print(f\"Running at Dropout: {p}\")\n",
        "    print(\"\\n\")\n",
        "    results.append(eval_config(f\"dropout_{p}\", dropout_p=p))\n",
        "\n",
        "# Optimizer: SGD, Adam, RMSProp\n",
        "for opt in [\"sgd\",\"adam\",\"rmsprop\"]:\n",
        "    print(f\"Running with Optimizer: {opt}\")\n",
        "    print(\"\\n\")\n",
        "    results.append(eval_config(f\"opt_{opt}\", opt_name=opt))\n"
      ],
      "metadata": {
        "id": "vVCxvd0nm8Hc"
      },
      "id": "vVCxvd0nm8Hc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot accuracy versus experiment config, BWT versus experiment config"
      ],
      "metadata": {
        "id": "IUkVXRBC_7Gk"
      },
      "id": "IUkVXRBC_7Gk"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.rcParams.update({\n",
        "    \"font.size\": 12,\n",
        "    \"axes.titlesize\": 13,\n",
        "    \"axes.labelsize\": 12\n",
        "})\n",
        "\n",
        "summary = pd.DataFrame([{k:v for k,v in r.items() if k != \"R_\"} for r in results]).sort_values(\"tag\")\n",
        "print(summary[[\"tag\",\"depth\",\"dropout_p\",\"loss_name\",\"opt_name\",\"ACC\",\"BWT\"]].to_string(index=False))\n",
        "\n",
        "TITLE_FOR = {\n",
        "    \"depth_\":   \"Network Depth\",\n",
        "    \"dropout_\": \"Dropout Probability\",\n",
        "    \"opt_\":     \"Optimizer\",\n",
        "    \"reg_\":     \"Regularizer\",\n",
        "}\n",
        "\n",
        "ORDER_FOR = {\n",
        "    \"opt_\": [\"sgd\", \"adam\", \"rmsprop\"],\n",
        "    \"reg_\": [\"nll\", \"l1\", \"l2\", \"l1+l2\"],\n",
        "}\n",
        "\n",
        "def _prep_subset(df, prefix):\n",
        "    sub = df[df[\"tag\"].str.startswith(prefix)].copy()\n",
        "\n",
        "    parts = sub[\"tag\"].str.split(pat=\"_\", n=1, expand=True)\n",
        "    sub[\"x\"] = parts[1]\n",
        "\n",
        "\n",
        "    if prefix == \"depth_\":\n",
        "        sub[\"sort\"] = sub[\"x\"].astype(int)\n",
        "        sub = sub.sort_values(\"sort\")\n",
        "    elif prefix == \"dropout_\":\n",
        "        sub[\"sort\"] = sub[\"x\"].astype(float)\n",
        "        sub = sub.sort_values(\"sort\")\n",
        "        sub[\"x\"] = sub[\"sort\"].map(lambda v: f\"{v:.1f}\")\n",
        "    elif prefix == \"opt_\":\n",
        "        order = [\"sgd\", \"adam\", \"rmsprop\"]\n",
        "        sub[\"x\"] = pd.Categorical(sub[\"x\"], categories=order, ordered=True)\n",
        "        sub = sub.sort_values(\"x\")\n",
        "    elif prefix == \"reg_\":\n",
        "        order = [\"nll\", \"l1\", \"l2\", \"l1+l2\"]\n",
        "        sub[\"x\"] = pd.Categorical(sub[\"x\"], categories=order, ordered=True)\n",
        "        sub = sub.sort_values(\"x\")\n",
        "\n",
        "    return sub\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bar_for(metric, prefix):\n",
        "    sub = _prep_subset(summary, prefix)\n",
        "    x = sub[\"x\"].astype(str).tolist()\n",
        "    y = sub[metric].to_numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6,3))\n",
        "    xticks = np.arange(len(x))\n",
        "    bars = ax.bar(xticks, y)\n",
        "\n",
        "    ax.set_xticks(xticks)\n",
        "    ax.set_xticklabels(x)\n",
        "\n",
        "    xlabel = TITLE_FOR.get(prefix, prefix)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(metric)\n",
        "    title_left = \"Backward Transfer (BWT)\" if metric == \"BWT\" else \"Average Accuracy (ACC)\"\n",
        "    ax.set_title(f\"{title_left} vs {xlabel}\")\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "\n",
        "    if metric == \"BWT\":\n",
        "        ax.set_ylim(-1.0, 0.1)\n",
        "        ax.axhline(0, color='black', linewidth=1)\n",
        "    else:\n",
        "        ax.set_ylim(0.0, 1.0)\n",
        "\n",
        "    ax.bar_label(bars, labels=[f\"{v:.2f}\" for v in y], padding=2)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "bar_for(\"ACC\",\"depth_\");   bar_for(\"BWT\",\"depth_\")\n",
        "bar_for(\"ACC\",\"reg_\");     bar_for(\"BWT\",\"reg_\")\n",
        "bar_for(\"ACC\",\"dropout_\"); bar_for(\"BWT\",\"dropout_\")\n",
        "bar_for(\"ACC\",\"opt_\");     bar_for(\"BWT\",\"opt_\")\n"
      ],
      "metadata": {
        "id": "oTmsa_VI3hAE"
      },
      "id": "oTmsa_VI3hAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the validation drop between tasks"
      ],
      "metadata": {
        "id": "DRd46vSqAIqd"
      },
      "id": "DRd46vSqAIqd"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_validation_drop_from_R(R, title=\"Validation accuracy drop after all 10 tasks\"):\n",
        "    N = R.shape[0]\n",
        "    acc_after_learn = np.array([R[i, i] for i in range(N)])\n",
        "    acc_after_all   = R[-1, :N]\n",
        "    delta = acc_after_all - acc_after_learn\n",
        "\n",
        "    x = np.arange(1, N+1)\n",
        "\n",
        "    plt.figure(figsize=(6.5, 3.2))\n",
        "    bars = plt.bar(x, delta)\n",
        "    plt.axhline(0, linewidth=1, color='black')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "    plt.xlabel(\"Task\")\n",
        "    plt.ylabel(\"Δ val acc (final − immediate)\")\n",
        "    plt.title(title)\n",
        "    plt.ylim(-1.0, 0.1)\n",
        "    plt.xticks(x)\n",
        "\n",
        "    for b, v in zip(bars, delta):\n",
        "        plt.text(b.get_x() + b.get_width()/2, v + (0.01 if v >= 0 else -0.03),\n",
        "                 f\"{v:.2f}\", ha='center', va='top' if v < 0 else 'bottom', fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_validation_drop_for_run(results, tag_to_use=None):\n",
        "    if tag_to_use is None:\n",
        "        preferred = [\"reg_nll\", \"opt_sgd\", \"opt_adam\", \"depth_3\", \"dropout_0.2\"]\n",
        "        chosen = None\n",
        "        for p in preferred:\n",
        "            chosen = next((r for r in results if r.get(\"tag\") == p and \"R_\" in r), None)\n",
        "            if chosen is not None:\n",
        "                break\n",
        "        if chosen is None:\n",
        "            chosen = next((r for r in results if \"R_\" in r), None)\n",
        "    else:\n",
        "        chosen = next((r for r in results if r.get(\"tag\") == tag_to_use and \"R_\" in r), None)\n",
        "\n",
        "    if chosen is None:\n",
        "        raise ValueError(\"No run with an R_ matrix found in `results`. Make sure you keep R_ when saving results.\")\n",
        "\n",
        "    R = np.asarray(chosen[\"R_\"])\n",
        "    plot_validation_drop_from_R(R, title=f\"Validation accuracy drop after all tasks ({chosen['tag']})\",\n",
        "                                savepath=\"figs/forgetting_curves.png\")\n",
        "\n",
        "\n",
        "plot_validation_drop_for_run(results, tag_to_use=\"reg_nll\")\n"
      ],
      "metadata": {
        "id": "jJHm0K0Q8T4U"
      },
      "id": "jJHm0K0Q8T4U",
      "execution_count": null,
      "outputs": []
    }
  ]
}